//------------------------------------------------------------------------------
// <auto-generated>
//     This code was generated by a tool.
//     Runtime Version:4.0.30319.18444
//
//     Changes to this file may cause incorrect behavior and will be lost if
//     the code is regenerated.
// </auto-generated>
//------------------------------------------------------------------------------
using System;
using System.Text;
using System.Linq;
using System.Collections.Generic;

using UnityEngine;

namespace AI
{
	
	[Serializable]
	public class QLearningProperties {
		// NOTE Default values as defined in http://sarvagyavaish.github.io/FlappyBirdRL/.
		
		// alpha
		[Range(0,1)]
		public float learningRate = 0.7f;
		
		// gamma
		[Range(0, 1)]
		public float discountRate = 1.0f;
		
		// epsilon
		[Range(0, 1)]
		public float explorationRate = 0.0f;

	}

	public interface IQValueStore<State, Action> {
		// Returns the qValue associated with the respective state-action tuple.
		// Returns 0.0f if the action is not yet registered in the mentioned state.
		float GetQValue(State state, Action action);

		// Retrieves the best action available from within the provided actions List
		// and the state. Returns a pair containing the best action for the given state
		// along its respective qValue.
		KeyValuePair<Action, float> GetBestAction(State state, List<Action> actions);

		// Updates or sets the state-action qValue  
		void SetQValue(State state, Action action, float qValue);
	}
	
	// Reference: Artificial Intelligence for Games 2nd Edition
	//				Ian Millington, John Funge
	//				Chapter 7.7.4
	[Serializable]
	public class QValueStore<QState, QAction> : IQValueStore<QState, QAction> where QState : class where QAction : class {
		// Based on a Map for convenience. As recommended by Millingotn and Funge in 7.7.5,
		// an array representation can also be used if space is limited.
		private Dictionary<QState, Dictionary<QAction, float> > store = new Dictionary<QState, Dictionary<QAction, float> >();
		
		public float GetQValue(QState state, QAction action) {
			// 0 signifies the default value
			float qValue = 0.0f;
			
			Dictionary<QAction, float> actions = null;
			if (store.TryGetValue(state, out actions)) {
				actions.TryGetValue(action, out qValue);
			}
			
			return qValue;
		}
		
		public KeyValuePair<QAction, float> GetBestAction(QState state, List<QAction> actions) {
			KeyValuePair<QAction, float>? best = null;
			
			Dictionary<QAction, float> registeredActions = null;
			if (store.TryGetValue(state, out registeredActions)) {
				
				// Iterate over all possible actions. Not just the ones
				// registered in the store.
				foreach (QAction action in actions) {
					// 0 signifies the default value
					float qValue = 0.0f;
					registeredActions.TryGetValue(action, out qValue);
					
					if (best == null || qValue > best.Value.Value) {
						// Need to create a new object since Key is not modifiable...
						best = new KeyValuePair<QAction, float>(action, qValue);
					}
				}
				
			}
			
			if (best == null) {
				best = new KeyValuePair<QAction, float>((actions.Count > 0 ? actions[0] : null), 0.0f);
			}
			
			return best.Value;
		}
		
		public void SetQValue(QState state, QAction action, float qValue) {
			if (!store.ContainsKey(state)) {
				store.Add(state, new Dictionary<QAction, float>());
			}
			
			Dictionary<QAction, float> actions = store[state];
			
			if (!actions.ContainsKey(action)) {
				actions.Add(action, 0.0f);
			}
			
			actions[action] = qValue;
		}
		
		public override string ToString() {
			StringBuilder builder = new StringBuilder();
			
			foreach (KeyValuePair<QState, Dictionary<QAction, float> > state in store) {
				foreach (KeyValuePair<QAction, float> action in state.Value) {
					builder.Append(state.Key.ToString() + " " + action.Key.ToString() + ": " + action.Value + "\n");
				}
			}
			
			return builder.ToString();
		}
		
	}

	// Reference: Artificial Intelligence for Games 2nd Edition
	//				Ian Millington, John Funge
	//				Chapter 7.7.
	public class CoalescedQValueStore<QState, QAction> : IQValueStore<QState, QAction> where QState : class where QAction : class {

		private class StateActionPair {

			public StateActionPair(QState state, QAction action) {
				State = state;
				Action = action;
			}

			public QState State { get; set; }
			public QAction Action { get; set; }
			
			public override bool Equals(object other) {
				StateActionPair rhs = other as StateActionPair;
				
				if (rhs != null) {
					return State.Equals(rhs.State) && Action.Equals(rhs.Action);
				}
				
				return false;
			}
			
			public override int GetHashCode() {
				// Reference: http://stackoverflow.com/questions/11795104/is-the-hashcode-function-generated-by-eclipse-any-good
				const int prime = 31;
				int hashCode = 1;
				
				hashCode = prime * hashCode + State.GetHashCode();
				hashCode = prime * hashCode + Action.GetHashCode();
				
				return hashCode;
			}

		}
		
		// Unlike the default QValueStore, this implementation hashes the state-action pair and takes
		// considers the tuple as one entity
		private Dictionary<StateActionPair, float> store = new Dictionary<StateActionPair, float>();
		
		public float GetQValue(QState state, QAction action) {
			// 0 signifies the default value
			float qValue = 0.0f;
			store.TryGetValue(new StateActionPair(state, action), out qValue);
			return qValue;
		}
		
		public KeyValuePair<QAction, float> GetBestAction(QState state, List<QAction> actions) {
			KeyValuePair<QAction, float>? best = null;

			// Iterate over all possible actions. Not just the ones
			// registered in the store.
			foreach (QAction action in actions) {
				// 0 signifies the default value
				float qValue = 0f;
				store.TryGetValue(new StateActionPair(state, action), out qValue);

				if (best == null || qValue > best.Value.Value) {
					// Need to create a new object since Key is not modifiable...
					best = new KeyValuePair<QAction, float>(action, qValue);
				}
			}
				
			if (best == null) {
				best = new KeyValuePair<QAction, float>((actions.Count > 0 ? actions[0] : null), 0.0f);
			}
			
			return best.Value;
		}
		
		public void SetQValue(QState state, QAction action, float qValue) {
			StateActionPair key = new StateActionPair(state, action);

			if (!store.ContainsKey(key)) {
				store.Add(key, 0.0f);
			}

			store[key] = qValue;
		}
	}

	// Reference: Artificial Intelligence for Games 2nd Edition
	//				Ian Millington, John Funge
	//				Chapter 7.7.4
	public interface ReinforcementProblem<State, Action> where State : class where Action : class {

		List<Action> GetAvailableActions(State state);

	}

	public class NullReinforcementProblem<State, Action> : ReinforcementProblem<State, Action> where State : class where Action : class {
	
		private static Action[] DEFAULT = { default(Action) };
		private static List<Action> EMPTY = new List<Action>(DEFAULT);

		public List<Action> GetAvailableActions(State state) {
			return EMPTY;
		}

	}
	
	// Reference: Artificial Intelligence for Games 2nd Edition
	//				Ian Millington, John Funge
	//				Chapter 7.7.3
	[Serializable]
	public class QLearning<QState, QAction> where QState : class where QAction : class {

//		private IQValueStore<QState, QAction> store = new QValueStore<QState, QAction>();
		private IQValueStore<QState, QAction> store = new CoalescedQValueStore<QState, QAction>();

		public QLearning() :
			this(new NullReinforcementProblem<QState, QAction>()) {
		}
		
		public QLearning(ReinforcementProblem<QState, QAction> problem) :
			this(problem, new QLearningProperties()) {
		}

		public QLearning(ReinforcementProblem<QState, QAction> problem, QLearningProperties properties) {
			this.Properties = properties;
			this.Problem = problem;
		}

		public QLearningProperties Properties { get; set; }

		public ReinforcementProblem<QState, QAction> Problem { get; set; }

		public void Update(QState state, QAction action, float reward, QState newState) {
			Update(state, action, reward, newState, Problem.GetAvailableActions(newState));
		}
		
		public void Update(QState state, QAction action, float reward, QState newState, List<QAction> newActions) {
			
			float newQValue = Reinforce(state, action, reward, newState, newActions);

			store.SetQValue(state, action, newQValue);

		}

		public QAction Explore(QState state) {
			return Explore(state, Problem.GetAvailableActions(state));
		}

		public QAction Explore(QState state, List<QAction> actions) {
			QAction action = null;
			// In case the exploration is triggered
			if (Properties.explorationRate == 0) {
				action = store.GetBestAction (state, actions).Key;
			} else if (UnityEngine.Random.Range (0.0f, 1.0f) < Properties.explorationRate) {
				action = actions [UnityEngine.Random.Range (0, actions.Count)];
			}
			return action;
		}

		private float Reinforce(QState state, QAction action, float reward, QState newState, List<QAction> newActions) {
			float currentQValueForStateAction = store.GetQValue(state, action);
			float currentBestQValueForNewState = store.GetBestAction(newState, newActions).Value;

//			var value = currentQValueForStateAction + Properties.learningRate 
//				* (reward + Properties.discountRate * currentBestQValueForNewState - currentQValueForStateAction);
			
			var reinforceValue = Mathf.Lerp (currentQValueForStateAction,
									(reward + (Properties.discountRate * currentBestQValueForNewState)),
									Properties.learningRate
								);
			return reinforceValue;
		}

		public override string ToString() {
			return store.ToString();
		}

	}

} // namespace AI